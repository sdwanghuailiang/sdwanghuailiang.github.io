[{"title":"Redis 探讨（二）： Redis 4.0.1 配置文件详解","date":"2017-08-27T03:55:42.000Z","path":"2017/08/27/20170827001/","text":"Redis 4.0.1 常用的配置文件是 redis.conf 和 sentinel.conf 这俩配置文件都在 redis 的根目录下，下面我们就简单说明一下这两个配置文件中的各个配置项。其实Redis配置文件中的描述已经很详细了，本文完全是为了自己更好的熟悉Redis的各个配置。 redis.conf 详解首先，启动Redis时，需要指定配置文件路径，例如：./redis-server /path/to/redis.conf，否则，Redis将以默认配置文件启动。在该配置文件中配置内存大小或者空间大小时，可以用1k 5GB 4M等形式来指定： 1k =&gt; 1000 bytes 1kb =&gt; 1024 bytes 1m =&gt; 1000000 bytes 1mb =&gt; 1024*1024 bytes 1g =&gt; 1000000000 bytes 1gb =&gt; 102410241024 bytes另外，Redis的配置大小写是不敏感的，所以1GB 1Gb 1gB表达的意思是一样的。 &lt;!– 这里需要一点 CSS 知识，选择器的问题，首先 &lt;th&gt; 存在于 &lt;table&gt; 中；其次 th:first-of-type 的意思是每个 &lt;th&gt; 为其父级的第一个元素，这里指的就是围绕着【名称】的 &lt;th&gt;。同理第二、三个使用 th:nth-of-type(2)、th:nth-of-type(3) 就可以了，以此类推。上述的 th:first-of-type 等于 th:nth-of-type(1) –&gt; &lt;style&gt;table th:first-of-type(1) { width: 30%;}table th:nth-of-type(2) { width: 70%;}&lt;/style&gt; 配置项 说明 导入外部配置文件 这个在引用通用的配置模板时很有用 include xx.conf 用于包含一个或多个配置文件，特别是引用通用的配置时，为了避免该配置文件中的配置被重写，最好把include写在最后一行，因为Redis总是采用最后一个配置作为配置指令的值。 启动时加载的模块 模块系统时Redis 4.0加入的 这个系统可以让用户通过自己编写的代码来扩展和实现 Redis 本身并不具备的功能 loadmodule xx.so 加载模块，该模块会在Redis启动时加载，如果服务器不能记载模块，则终止加载，可以使用多个loadmodule命令加载多个模块。 网络配置 bind 127.0.0.1 绑定的主机地址，默认是127.0.0.1，如果不设置，会处理所有的网络接口请求，一台服务器可以有多个网络接口（也就是网卡），每个网络接口都有自己的IP地址，如果不绑定，则这些网络接口都接受请求，如果设置，则只接受制定的网络地址请求，多个IP地址用空格隔开。 protected-mode yes 3.2加入的参数，是否开启保护模式，默认开启。要是配置里没有指定bind和密码，开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码和bind，可以开启。否则最好关闭，设置为no port 6379 redis监听的端口号，默认为6379，如果设为0，redis将不在socket 上监听任何客户端连接 tcp-backlog 511 此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p unixsocket /tmp/redis.sock 指定redis监听的unix socket路径，默认不启用 unixsocketperm 700 配置unix socket使用文件的权限 timeout 0 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0（也就是一个 client 空闲多少秒之后关闭连接（0表示永不关闭）） 。 tcp-keepalive 300 单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方给出的建议值是300s，如果设置为0，则不会周期性的检测 一般配置 daemonize no 默认情况下 redis 不是作为守护进程运行的，如果你想让它在后台运行，你就把它改成 yes。当redis作为守护进程运行的时候，它会写一个 pid 到pidfile配置的文件里面。 supervised no 可以通过upstart和systemd管理Redis守护进程。选项：supervised no - 没有监督互动 supervised upstart - 通过将Redis置于SIGSTOP模式来启动信号 supervised systemd - signal systemd将READY = 1写入$ NOTIFY_SOCKET supervised auto - 检测upstart或systemd方法基于 UPSTART_JOB或NOTIFY_SOCKET环境变量 pidfile /var/run/redis_6379.pid 配置PID文件（redis进程文件）路径，当redis作为守护进程运行的时候，它会把 pid 默认写到该文件里面。 loglevel notice 定义日志级别。可以是下面的这些值：debug（记录大量日志信息，适用于开发、测试阶段）verbose（较多日志信息，但是没有debug级别信息多）notice（适量日志信息，使用于生产环境）warning（仅有部分重要、关键信息才会被记录） logfile “” 日志文件的位置，当指定为空字符串时，为标准输出，如果redis已守护进程模式运行，那么日志将会输出到/dev/null。 syslog-enabled no 要想把日志记录到系统日志，就把它改成 yes，也可以可选择性的更新其他的syslog 参数以达到你的要求。 syslog-ident redis 设置系统日志的标识符 syslog-facility local0 指定系统日志设置，必须是 USER 或者是 LOCAL0-LOCAL7 之间的值 databases 16 设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select &lt;dbid&gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值。 always-show-logo yes Redis 4.0加入的配置，是否一直显示图标。 快照配置 save &lt;seconds&gt; &lt;changes&gt; 存 DB 到磁盘，可以配置多个：格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;根据给定的时间间隔和写入次数将数据保存到磁盘.下面的例子的意思是：save 900 1save 300 10save 60 10000900 秒内如果至少有 1 个 key 的值变化，则保存。300 秒内如果至少有 10 个 key 的值变化，则保存。60 秒内如果至少有 10000 个 key 的值变化，则保存。注意：你可以注释掉所有的 save 行来停用保存功能。也可以直接一个空字符串来实现停用：save “”。 stop-writes-on-bgsave-error yes 当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误。如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。这样做的好处在于可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。如果下一次RDB持久化成功，redis会自动恢复接受写请求。如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，以便在快照写入失败时，也能确保redis继续接受新的写请求。 rdbcompression yes 对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。 rdbchecksum yes 是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验值。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。 dbfilename dump.rdb 设置快照的文件名 dir ./ 设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名，数据库的写入会在这个目录，rdb、aof文件也会写在这个目录。 主从配置 slaveof &lt;masterip&gt; &lt;masterport&gt; 主从复制，使用 slaveof 来让一个 redis 实例成为另一个reids 实例的副本，默认关闭。注意这个只需要在 slave 上配置 masterauth &lt;master-password&gt; 如果master设置了requirepass，需要密码认证，那么slave要连上master，需要有master的密码才行，masterauth就是用来配置master的密码，这样可以在连上master后进行认证，默认不设置。 slave-serve-stale-data yes 当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现：如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候。如果为 no ，在你执行除了 info 和 salveof 之外的其他命令时，slave 都将返回一个 “SYNC with master in progress” 的错误。 slave-read-only yes 你可以配置一个 slave 实体是否接受写入操作。通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，因为相对从 master 重新同步数而言，据数据写入到 slave 会更容易被删除。但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。从 redis 2.6 版起，默认 slaves 都是只读的。 repl-diskless-sync no 是否使用socket方式复制数据。目前redis复制提供两种方式，disk（硬盘备份）和socket（无硬盘备份）。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快也就是硬盘低速而网络高速（高带宽）的情况下推荐用socket（无硬盘备份）方式。 repl-diskless-sync-delay 5 当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站（slave）传送RDB文件，这个等待时间是可配置的。这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站（slave）服务。从站（slave）则要排队等待下一次RDB传送。因此服务器等待一段时间以期更多的从站（slave）到达。延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。 repl-ping-slave-period 10 slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过repl_ping_slave_period 来设置，默认10秒。 repl-timeout 60 主从复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，否则每次主站和从站之间通信低速时都会被检测为超时。 repl-disable-tcp-nodelay no 同步之后是否禁用从站（slave）上的TCP_NODELAY，可设置yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，即在高负载情况下或者在主从都掉线的情况下建议选择yes。 repl-backlog-size 1mb 复制缓冲区大小，这是一个累加的缓冲区，用来保存最新复制的命令，当从站断开一段时间的情况时，它替从站接收存储数据。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。 repl-backlog-ttl 3600 master没有slave连接时，一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒，秒数从最后一个从服务器断开的时间开始计算，值为0表示不释放。需要注意的是，从服务器没有该超时时间，因为他们可能会被提升为主服务器，并且能够与其下的从服务器重新同步，所以从服务器的缓冲区应该总是能够积累缓存。 slave-priority 100 当master不可用，Redis Sentinel（哨兵）会根据slave的优先级选举一个提升为master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。默认优先级是100。 min-slaves-to-write 3 redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write N，健康的slave（在线的从服务器）的个数小于N，mater就禁止写入。master最少得有N个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave（在线的从服务器）的时候，master不能写入来避免数据丢失。设置为0是关闭该功能，默认是0。 min-slaves-max-lag 10 配合min-slaves-to-write使用，设置延时多少秒的slave才被认为是健康的slave, 默认是10秒，延迟的秒数必须&lt;=所定义的值，延迟秒数是从最后一次收到的来自从站的ping开始计算。ping通常是每秒一次。 slave-announce-ip 5.5.5.5 slave-announce-ip和slave-announce-port配置是Redis 3.2.2加上的。在端口转发或地址转换（NAT）网络环境中，如果Redis和Sentinel做了端口映射，例如在Docker默认网络模式下，使用-p参数做端口映射，就需要配置一下从服务器（slave）redis.conf中的slave-announce-ip 和 slave-announce-port，对应外网的IP和外网端口。Sentinel的配置文件sentinel.conf 也需要配置sentinel announce-ip 和 sentinel announce-port ，对应外网的IP和外网端口。当然，如果Docker配置成host网络模式，就不需要配置了。 slave-announce-port 1234 配合slave-announce-ip使用。 安全配置 requirepass foobared requirepass配置可以让用户使用AUTH命令来认证连接密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户的redis都是跑在内网的服务器，也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。 rename-command CONFIG “” 将命令重命名，为了安全考虑，可以将某些重要的、危险的命令重命名，比如 CONFIG 命令，这样用户不能使用，而内部工具还能接着使用。当你把某个命令重命名成空字符串的时候就等于取消了这个命令。 需要注意的是，登陆或者和从服务器之间进行传输连接传输的命令不要重命名，不然会出现问题。 客户端配置 maxclients 10000 设置能连上redis的最大客户端连接数量，默认是10000个客户端连接，如果设置 maxclients为0，表示不作限制。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。 内存管理配置 maxmemory &lt;bytes&gt; redis配置的最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先配合maxmemory-policy策略进行处理，即清除已到期或即将到期的Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。 maxmemory-policy noeviction 当内存使用达到最大值时，redis使用的删除策略。有以下几种策略可以选择，默认是noeviction（LRU是最近才使用的，LFU是最不常用的。LRU，LFU和volatile-ttl都是用近似的方法实现的）：volatile-lru -&gt; 利用LRU算法移除设置过过期时间的key。allkeys-lru -&gt; 利用LRU算法移除任何key。volatile-lfu -&gt; 从设置过过期时间的key集合中移除最不常用的key。allkeys-lfu -&gt; 从最不常用的key中移除任何的key。volatile-random -&gt; 随机移除设置过过期时间的key。allkeys-random -&gt; 随机移除任何key。volatile-ttl -&gt; 移除即将过期的key，根据最近过期时间来删除（较小的TTL值）。noeviction -&gt; 不移除任何key，只是返回一个写错误 ，默认选项。注意：上面的这些移除策略，如果redis没有合适的key移除，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。 maxmemory-samples 5 LRU，LFU和minimal TTL算法不是精确的算法，而是近似的算法(为了节省内存)，所以你可以改变样本大小对它进行调优以达到更快的速度或更精确的精度。默认情况下，Redis会选择5个样本进行检测，检查5个key并选择最近使用过的一个key，因为5个key已经可以产生足够精确的结果，10个key会非常接近于真实的LRU，但是需要消耗更多的CPU，3个key速度会很快，但是结果不准确。 惰性删除（非阻塞删除）配置 默认情况下是以阻塞的方式删除对象，和DEL命令一样，阻塞删除时，服务器会停止处理新的命令，以便回收对象所占的内存。如果删除的key关联的是一个小对象，则删除的时间会非常短，但是，如果这个键与包含数百万个元素的聚合值相关联，那么服务器可以阻塞很长时间来完成操作。这种情况下，可以将对象删除策略配置为非阻塞删除，和UNLINK、FLUSHDB和FLUSHDB命令的异步选项一样，以在后台回收内存。 lazyfree-lazy-eviction no 达到最大内存后，移除对象时的删除策略。 lazyfree-lazy-expire no 对象达到过期时间时的删除策略 lazyfree-lazy-server-del no Redis服务器删除key或者刷新数据库时的删除策略 slave-lazy-flush no 从服务器执行重新同步操作或者删除整个数据库以便加载RDB文件时的删除策略。 仅追加模式配置 默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失（取决于配置的保存点），Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，redis宕机或服务器断电时只丢失一秒的数据。如果在启动时启用了AOF，启动时Redis都会先把这个AOF文件的数据读入内存里，先忽略RDB文件。可以同时启用AOF和RDB两种持久化方式。 appendonly no 是否启用AOF持久化，默认不开启 appendfilename “appendonly.aof” AOF持久化文件名，默认时appendonly.aof appendfsync everysec aof持久化策略的配置，调用fsync()告诉操作系统在磁盘上写入数据：no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。always表示每次写入都执行fsync，以保证数据同步到磁盘。everysec表示每秒执行一次fsync，可能会导致丢失这1s数据 no-appendfsync-on-rewrite no 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。 auto-aof-rewrite-percentage 100 aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用 BGREWRITEAOF 对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。 auto-aof-rewrite-min-size 64mb 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。 aof-load-truncated yes Redis所在得服务器崩溃宕机得时候，aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存，这时就可能发现AOF文件是不完整得。尤其在ext4文件系统没有加上data=ordered选项（redis自己宕机或者异常终止不会造成尾部不完整现象）时出现这种现象，可以选择让redis在系统错误时退出，或者导入尽可能多的数据（默认）。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个日志通知给客户端，然后加载一个截短得文件。如果是no，服务器就会出现错误并拒绝启动，用户必须手动redis-check-aof修复AOF文件才可以重新启动。 aof-use-rdb-preamble no Redis 4.0 新增了 RDB-AOF 混合持久化格式，这是一个可选的功能，在开启了这个功能之后，AOF 重写产生的文件将同时包含 RDB 格式的内容和 AOF 格式的内容，其中 RDB 格式的内容用于记录已有的数据，而 AOF 格式的内存则用于记录最近发生了变化的数据，这样 Redis 就可以同时兼有 RDB 持久化和 AOF 持久化的优点——既能够快速地生成重写文件，也能够在出现问题时，快速地载入数据。这个功能可以通过 aof-use-rdb-preamble 选项进行开启，默认不开启，这是为了避免格式更改出现意外，新部署得就无所谓了。 Lua脚本配置 lua-time-limit 5000 以毫秒为单位执行Lua脚本的最大执行时间。如果达到最大时间限制（毫秒），redis会记个log，然后返回错误的查询。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write写命令的脚本。如果已经调用了write写命令，SHUTDOWN NOSAVE将是关闭服务器的唯一方法。将其设置为0或负值，无限执行，无需警告。 redis集群配置 cluster-enabled yes 是否开启集群模式，默认不开启。 cluster-config-file nodes-6379.conf 集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis集群节点生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突。 cluster-node-timeout 15000 集群节点连接超时毫秒数 cluster-slave-validity-factor 10 在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。对于一个slave，没有什么简单的方法可以精确的测量它的数据年龄，因此需要进行以下两项检查：1.如果多个slave服务器都能够进行故障转移，他们就会交换消息，以试图以最佳的复制偏移量(来自于master的更多数据)给slave提供转移优势。2.每一个slave都计算最后一次与master互动的时间，这个时间可能是最后一次ping操作，或者接收命令，或者与master断开的时间。如果最后一次交互时间过去太久，则该slave压根不会进行故障转移。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period。如果node-timeout为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移。 cluster-migration-barrier 1 迁移壁垒：Redis集群中的slave节点可以迁移到没有slave节点或者slave节点全部停止工作的master节点（孤儿节点）下，这种机制提高了Redis集群抵御故障的能力，不然的话，如果master节点下没有正在工作的slave节点，这台master节点就会成为孤儿节点。只有master的slave数量大于该值，其下的slave节点才能迁移到其他孤儿master节点上，他反映了集群中每一个master节点下拥有的slave节点的数量。如这个参数若被设为2，那么只有当一个主节点拥有2个可工作的从节点时，它的其中一个从节点会尝试迁移。默认值是1，即当master节点下至少有一个slave节点和他保持在一起时，其下其他的slave节点才能进行迁移。 要禁用slave节点迁移，只需要将改值设置为一个非常大的值就好。值可以设置为0，但这种配置会有危险，可以在开发调试时使用。 cluster-require-full-coverage yes 默认情况下，Redis集群中，如果有一个哈希槽没有可用的节点为他提供服务（也就是这个哈希槽不属于任何节点），redis集群就停止接受查询，也就是必须保证所有的哈希槽都正常，Redis集群才能提供服务。 当这个哈希槽有节点收回时，集群会自动开始提供服务。但是，有时候现在工作的是Redis集群的子集，仍然希望能提供服务这时就应该把该项设置为no。不建议开启该配置，这样集群分区的时候，小分区的master一直在接受写请求，但又无法查询，而造成很长时间数据不一致。 NAT 和 Docker配置 Redis 4.0 将兼容 NAT 和 Docker。在某些部署环境下，比如采用Docker或其他容器部署，这时的IP地址是处理过的，或者端口是转发后的，这种环境下，Redis集群节点地址发现就会失败。为了使Redis集群能在这种复杂环境下工作，需要将地址信息配置为静态的，即每个节点都配置为他的公共地址（包括IP地址，端口号、集群消息总线端口）。节点的公共信息在消息总线的数据包中能够找到，以便其他节点能够正确映射节点的地址。如果此处不配置，则将使用正常的Redis集群进行自动检测。注意：当重新映射的时候，总线端口可能不位于 端口号 + 10000的固定偏移量上，因此可以指定任何的端口和总线端口，如果不设置总线端口，通常使用10000的固定偏移量 cluster-announce-ip 10.1.1.5 节点的公网IP地址 cluster-announce-port 6379 节点的端口号 cluster-announce-bus-port 6380 总线端口号 慢请求日志配置 慢日志是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在慢日志中，慢日志保存在内存中，所以没有IO操作。 slowlog-log-slower-than 10000 执行时间比slowlog-log-slower-than大的请求记录到慢日志里面，单位是微秒，1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。 slowlog-max-len 128 慢查询日志所占的内存长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。 延迟监控配置 延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。 latency-monitor-threshold 0 延迟监控阈值（毫秒数），0的话，就是关闭监视。默认延迟监控功能是关闭的，因为如果您没有延迟问题，这个配置就不需要，并且它搜集数据对性能有影响，虽然影响非常小，但是负载大的话，效果就明显了。如果你需要打开，也可以通过CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;命令动态设置。 事件通知配置 键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态 notify-keyspace-events “” 参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：#K 键空间通知，所有通知以 keyspace@ 为前缀#E 键事件通知，所有通知以 keyevent@ 为前缀#g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知#$ 字符串命令的通知#l 列表命令的通知#s 集合命令的通知#h 哈希命令的通知#z 有序集合命令的通知#x 过期事件：每当有过期键被删除时发送#e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送#A 参数 g$lshzxe 的别名输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考Redis Keyspace Notifications。 高级配置 该设置是Redis的内存优化策略，将一个对象存储在hash类型中会占用更少的内存，并且可以更方便的存取整个对象。省内存的原因是新建一个hash对象时开始是用zipmap来存储的。这个zipmap其实并不是hash table，但是zipmap相比正常的hash实现可以节省不少hash本身需要的一些元数据存储开销。尽管zipmap的添加，删除，查找都是O(n)，但是由于一般对象的field数量都不太多。所以使用zipmap也是很快的,也就是说添加删除平均还是O(1)。如果field或者value的大小超出一定限制后，Redis会在内部自动将zipmap替换成正常的hash实现。以下是几篇Redis再内存优化方面的文章，感觉分析的不错，分享给各位：Redis短结构与分片Redis数据存储优化机制用最少的机器支撑万亿级访问，微博6年Redis优化历程Redis内存使用优化与存储美团在Redis上踩过的一些坑小的聚合类型数据的特殊编码处理30G 的redis 如何优化Redis常用内存优化手段与参数Redis优化经验总结(必看篇) hash-max-ziplist-entries 512 hash类型的数据结构在编码上可以使用ziplist和hashtable。ziplist的特点就是文件存储(以及内存存储)所需的空间较小,在内容较小时,性能和hashtable几乎一样。因此redis对hash类型默认采取ziplist。如果hash中条目的条目个数或者value长度达到阀值,将会被重构为hashtable。这个参数指的是ziplist中允许存储的最大条目个数，默认为512，建议为128。 hash-max-ziplist-value 64 ziplist中允许条目value值最大字节数，超过该值，采用hash，默认为64，建议为1024 list-max-ziplist-size -2 list也以一种特殊的方式进行编码，以节省大量空间。当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：-5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）-4: 每个quicklist节点上的ziplist大小不能超过32 Kb。-3: 每个quicklist节点上的ziplist大小不能超过16 Kb。-2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值，性能最高的选项通常是-2(8 Kb大小)或-1(4 Kb大小)）-1: 每个quicklist节点上的ziplist大小不能超过4 Kb。 list-compress-depth 0 列表也可以被压缩，这个参数表示一个quicklist两端不被压缩的节点个数。注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。参数list-compress-depth的取值含义如下：0: 是个特殊值，表示都不压缩。这是Redis的默认值。1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。依此类推…由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。 set-max-intset-entries 512 当set集合中的元素为整数且元素个数小于配置set-max-intset-entries值时，使用intset数据结构存储，否则转化为Dict结构，Dict实际是Hash Table的一种实现，key为元素值，value为NULL，这样即可在O(1)时间内判断集合中是否包含某个元素。intset中有三种类型数组：int16_t类型、int32_t 类型、 int64_t 类型。至于怎么选择是那种类型的数组，是根据其保存的值的取值范围来决定的，初始化时是 int16_t，根据 set 中的最大值在[INT16_MIN, INT16_MAX] , [INT32_MIN, INT32_MAX], [INT64_MIN, INT64_MAX]的那个取值范围来动态确定整个数组的类型。例如set一开始是 int16_t 类型，当一个取值范围在 [INT32_MIN, INT32_MAX]的值加入到 set 时，则将保存 set 的数组升级成 int32_t 的数组。 zset-max-ziplist-entries 128 根hash和list一样sorted set也有节约内存的方式，当sorted set的元素个数及元素大小小于一定限制时，它是用ziplist来存储。 zset-max-ziplist-value 64 配置value最大为64字节。 hll-sparse-max-bytes 3000 value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse）。大于hll-sparse-max-bytes使用稠密的数据结构（dense），一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。 activerehashing yes Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。 client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt; 对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。class：客户端类型，取值normal（普通的客户端）、slave（从库的复制客户端）、pubsub（发布与订阅的客户端）。hard limit：缓冲区大小的硬性限制，即buffer最大值,一旦达到阀值将立即关闭连接。soft limit：缓冲去大小的软性限制，它和seconds配合,如果buffer值超过soft且持续时间达到了seconds,也将立即关闭连接,如果超过了soft但是在seconds之后，buffer数据小于了soft,连接将会被保留。soft seconds：缓冲区大小达到了（超过）soft limit值的持续时间，单位是秒。其中hard和soft都设置为0,则表示禁用buffer控制.通常hard值大于soft。 client-output-buffer-limit normal 0 0 0 对于normal client（正常客户端，包括监控客户端），第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。 client-output-buffer-limit slave 256mb 64mb 60 对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。 client-output-buffer-limit pubsub 32mb 8mb 60 对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。 hz 10 Redis 调用内部函数来执行许多后台任务，如关闭客户端超时的连接，清除过期的Key等等。不是所有的任务都以相同的频率执行，但 Redis 依照指定的“Hz”值来执行检查任务。默认情况下，“Hz”的被设定为 10 。提高该值将在 Redis 空闲时使用更多的 CPU 时，但同时当有多个 key 同时到期会使 Redis 的反应更灵敏，以及超时可以更精确地处理。范围是 1 到 500 之间，但是最好不要超过100。大多数用户应该使用 10 这个默认值，只有在非常低的延迟的情况下有必要提高最大到 100 。 aof-rewrite-incremental-fsync yes 在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync进行同步。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。 LFU驱逐策略 从Redis4.0开始，一个新的LFU（Least Frequently Used）驱逐策略被引入，和绝大多数新加入的配置一样，该配置默认也是关闭的。在说明该驱逐策略之前，我们先简单说下LFU算法的基本原理：LFU（Least Frequently Used）最近最少使用算法，看名字就知道是个基于访问频次的一种算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间（会将时间上最不常访问的数据给淘汰），而LFU是基于访问次数的。举个简单的例子：假设缓存大小为3，数据访问序列为set(2,2),set(1,1),get(2),get(1),get(2),set(3,3),set(4,4)，则在set(4,4)时对于LFU算法应该淘汰(3,3)，而LRU应该淘汰(1,1)。那么LFU Cache应该支持的操作为：get(key)：如果Cache中存在该key，则返回对应的value值，否则，返回-1；set(key,value)：如果Cache中存在该key，则重置value值；如果不存在该key，则将该key插入到到Cache中，若Cache已满，则淘汰最少访问的数据。为了能够淘汰最少使用的数据，因此LFU算法最简单的一种设计思路就是 利用一个数组存储 数据项，用hashmap存储每个数据项在数组中对应的位置，然后为每个数据项设计一个访问频次，当数据项被命中时，访问频次自增，在淘汰的时候淘汰访问频次最少的数据。这样一来的话，在插入数据和访问数据的时候都能达到O(1)的时间复杂度，在淘汰数据的时候，通过选择算法得到应该淘汰的数据项在数组中的索引，并将该索引位置的内容替换为新来的数据内容即可，这样的话，淘汰数据的操作时间复杂度为O(n)。另外还有一种实现思路就是利用 小顶堆+hashmap，小顶堆插入、删除操作都能达到O(logn)时间复杂度，因此效率相比第一种实现方法更加高效。综上，LFU更加偏向于随机性比较大的场景。说了一堆，是不是蒙圈了，下边咱们拿个网上的图来说一下： LFU淘汰过程 下面简单讲解一下:1. 假设我们的lfu最大的存储空间控制为5个，此时访问D,D现在的访问频率计数是26;2. 访问D后,D的频率+1,也就是27了。 此时需要调整缓存池数据需要重新排序,D和C交换;3. 访问B,B的频率+1,由于A的频率仍然比B大,所以不需要调整;4. 当新数据F插入缓存池之前,由于已经空间满了，需要干掉一个！ 因为E的频率最低,故淘汰E,将F插入缓存池,缓存池重新排序,F放到队尾。上面简单介绍了LFU算法，下边我们再说一下Redis 4.x中的LFU驱逐策略：Redis LFU实现中有两个可调参数：计数器对数因子和计数器衰减时间。LFU计数器每个键只有8位，最大值为255，所以Redis使用具有对数行为的概率增量。给定旧计数器的值，当访问一个密钥时，计数器以这种方式递增：1. 提取0和1之间的随机数R。2. 概率P被计算为1 /（old_value 乘以 lfu_log_factor + 1）。 3. 只有当”R&lt;P”时才会递增计数器。默认lfu-log-factor为10.这是一个表格，说明频率计数器如何随着不同对数因子的不同访问次数而变化： 注意：上表是通过运行以下命令获得的：＃redis-benchmark -n 1000000 incr foo＃redis-cli object freq foo＃注2：计数器初始值为5，以使新对象有机会累积命中。＃计数器衰减时间是为了使key计数器除以2，必须经过的时间（以分钟为单位）（如果key值小于&lt;= 10，则递减）。 lfu-log-factor 10 计数器对数因子，默认是10。 lfu-decay-time 1 计数器衰减时间，以分钟为单位，默认值为1，如果设置为0，意味着每次发生扫描时都会使计数器衰减。 碎片整理配置 Redis 4.0开始，添加了灵活的碎片处理机制。该特性需要Redis使用Jemalloc做内存管理，目前这个特性还处于实验阶段，但是已经通过了一段时间的测试。首先，我们先说说什么是灵活的碎片处理机制：碎片处理就是Redis服务器压缩在内存中分配给数据的空间，这样可以回收内存空间，一般情况下，碎片处理需要重启服务器，或者刷新所有的数据并重新创建，但是，从Redis 4.0开始，Redis处理碎片时，不需要重启服务器，碎片处理过程可以在运行状态下进行，类似于程序的热部署。基本上，当碎片超过一定级别（参见下边的配置选项）时，Redis会利用某些特定的Jemalloc特性来创建连续内存区域中的值的新副本（这是为了将其分配到更好的位置），同时释放数据的旧副本，并对所有的key重复此过程，以使内存碎片返回到正常值。注意：1. 默认情况下，该功能是禁用的。2. 如果没有碎片问题，不需要开启该功能。3. 一旦遇到碎片问题，您可以在需要时，使用”CONFIG SET activedefrag yes”命令启用此功能。4. 配置参数能够对内存碎片起到微调的作用，如果您不确定自己需要什么样的配置，请保持默认值不变。 activedefrag yes 启用活动碎片整理 active-defrag-ignore-bytes 100mb 开始进行活动碎片整理的最小碎片资源 active-defrag-threshold-lower 10 开始进行活动碎片整理的最小碎片百分比 active-defrag-threshold-upper 100 Redis尽力整理碎片后，最大碎片百分比 active-defrag-cycle-min 25 在CPU百分比最小为多少时，开始进行碎片处理 active-defrag-cycle-max 75 Redis尽力整理碎片后，最大的CPU百分比 sentinel.conf 详解Redis-Sentinel（一般成称为哨兵）是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。它的主要功能有以下几点： 不时地监控redis是否按照预期良好地运行; 如果发现某个redis节点运行出现状况，能够通知另外一个进程(例如它的客户端); 能够进行自动切换。当一个master节点不可用时，能够选举出master的多个slave(如果有超过一个slave的话)中的一个来作为新的master,其它的slave节点会将它所追随的master的地址改为被提升为master的slave的新地址。 需要注意的是，配置文件在sentinel运行期间是会被动态修改的，当slave升级为master时，配置文件被重写。例如当发生主备切换时候，master配置文件会被修改为另外一个slave的配置文件。这样，之后sentinel如果重启时，就可以根据这个配置来恢复其之前所监控的redis集群的状态。 配置项 说明 网络配置 bind 127.0.0.1 绑定的主机地址，默认是127.0.0.1，多个地址用空格隔开。 protected-mode no 是否开启保护模式，默认关闭。 port &lt;sentinel-port&gt; 哨兵实例运行的端口号，默认是26379。 sentinel announce-ip &lt;ip&gt; 在端口转发或地址转换（NAT）网络环境中，哨兵可以通过非本地地址从外部访问。 sentinel announce-port &lt;port&gt; ＃同样，当提供announce-port并且有效且非零时，哨兵会通知指定的TCP端口。 dir &lt;working-directory&gt; 哨兵工作时使用的临时文件夹。 故障转移配置 sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; 哨兵去监视一个名为master-name（master-name只能包含英文字母，数字，和“.-_”这三个字符，不能包含特殊字符和空格）的主redis实例，这个主实例的IP地址为本机地址ip（master-ip 要写真实的ip地址而不要用回环地址127.0.0.1），端口号为redis-port，而将这个主实例判断为失效至少需要quorum个哨兵进程的同意，只要同意哨兵的数量不达标，自动failover就不会执行。 sentinel auth-pass &lt;master-name&gt; &lt;password&gt; 设置连接master和slave时的密码，注意的是sentinel不能分别为master和slave设置不同的密码，因此master和slave的密码应该设置相同，而且如果集群中有Redis设置了密码，则其主从实例都应该设置密码。 sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; 指定了Sentinel认为Redis实例已经失效所需的毫秒数。当实例超过该时间没有返回心跳PING结果，或者直接返回错误，那么Sentinel将这个实例标记为主观下线（单方面地认为这个master已经不可用了(subjectively down, 也简称为SDOWN)）。只有一个 Sentinel进程将实例标记为主观下线并不一定会引起实例的自动故障迁移：只有在足够数量的Sentinel都将一个实例标记为主观下线之后，实例才会被标记为客观下线（objectively down， 简称 ODOWN ），这时自动故障迁移才会执行。单位是毫秒，默认是30秒。 sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt; 默认是1。选项指定了在执行故障转移时，最多可以有多少个从服务器同时对新的主服务器进行同步，这个数字越小，完成故障转移所需的时间就越长。如果从服务器被设置为允许使用过期数据集（参见对 redis.conf 文件中对 slave-serve-stale-data 选项的说明），那么你可能不希望所有从服务器都在同一时间向新的主服务器发送同步请求，因为尽管复制过程的绝大部分步骤都不会阻塞从服务器，但从服务器在载入主服务器发来的 RDB 文件时，仍然会造成从服务器在一段时间内不能处理命令请求：如果全部从服务器一起对新的主服务器进行同步， 那么就可能会造成所有从服务器在短时间内全部不可用的情况出现。你可以通过将这个值设为 1 来保证每次只有一个从服务器处于不能处理命令请求的状态。如果您使用从服务器提供查询，为了避免主备切换主从数据同步的过程中从服务器无法访问，请使用较低的数字。 sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; 故障转移超时时间，单位是毫秒，默认是3分钟。它可以用在如下几个方面：1. 同一个sentinel对同一个master两次failover之间的间隔时间。2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。3. 取消已经进行但未生成任何配置更改的failover所需的时间（SLAVEOF NO ONE尚未被提升的从站确认）。4. 当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了。 脚本配置 notification-script 和 reconfig-script是用来配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。对于脚本的运行结果有以下规则：若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; 通知型脚本，当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。 sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。以下参数将会在调用脚本时传给脚本:“&lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;”目前”&lt;state&gt;”总是“failover”, “&lt;role&gt;”是“leader”或者“observer”中的一个。参数 from-ip, from-port, to-ip, to-port是旧的master和新的master(即旧的slave)用来通信的。这个脚本应该是通用的，能被多次调用，不是针对性的。 好了，Redis配置文件介绍完了，下一讲，我们再说一下Redis的数据类型。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.jkinn.com/tags/Redis/"}]},{"title":"Redis 深入探讨（一）：Linux CentOS 7.3 安装 Redis 4.0.1","date":"2017-08-16T11:32:29.000Z","path":"2017/08/16/20170816001/","text":"Redis简介Redis 是完全开源免费的，是一个高性能的key-value数据库。Redis 与其他 key - value 缓存产品有以下三个特点：Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。Redis支持数据的备份，即master-slave模式的数据备份。性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s。 Redis 4.0 新特性Redis 4.x 相比 Redis 之前的版本，功能上有了很多改进，具体可参考以下几篇文章： http://blog.huangz.me/diary/2016/redis-4-outline.html https://www.oschina.net/news/79619/redis-4-0-rc1 http://www.cnblogs.com/lshs/p/6195257.html http://www.raincent.com/content-10-8073-1.html http://www.cnblogs.com/svan/p/7054129.html Redis 4.0.1 安装本文以opt目录作为安装目录进行安装，详细安装过程如下： 下载 Redis 4.0.1 12[root@localhost ~]# cd /opt[root@localhost opt]# wget http://download.redis.io/releases/redis-4.0.1.tar.gz 解压 redis-4.0.1.tar.gz 1[root@localhost opt]# tar -zxvf redis-4.0.1.tar.gz 编译进入 redis 目录，执行 make 命令进行编译： 12[root@localhost opt]# cd redis-4.0.1/[root@localhost redis-4.0.1]# make 进行编译时，有可能会报如下两个错误： 如果服务器未安装 gcc编译工具，则执行编译时，会报如下错误：1234567891011121314[root@localhost redis-4.0.1]# make............make[3]: gcc：命令未找到make[3]: *** [net.o] 错误 127make[3]: 离开目录“/opt/redis-4.0.1/deps/hiredis”make[2]: *** [hiredis] 错误 2make[2]: 离开目录“/opt/redis-4.0.1/deps”make[1]: [persist-settings] 错误 2 (忽略) CC adlist.o/bin/sh: cc: 未找到命令make[1]: *** [adlist.o] 错误 127make[1]: 离开目录“/opt/redis-4.0.1/src”make: *** [all] 错误 2 此时，执行 yum install gcc 安装 gcc编译工具 即可：12345678910111213[root@localhost redis-4.0.1]# yum install gcc............已安装: gcc.x86_64 0:4.8.5-11.el7 作为依赖被安装: glibc-devel.x86_64 0:2.17-157.el7_3.5 glibc-headers.x86_64 0:2.17-157.el7_3.5 作为依赖被升级: glibc.x86_64 0:2.17-157.el7_3.5 glibc-common.x86_64 0:2.17-157.el7_3.5 完毕！ 如果服务器没有安装 jemalloc，则会报如下错误：12345678910............In file included from adlist.c:34:0:zmalloc.h:50:31: 致命错误：jemalloc/jemalloc.h：没有那个文件或目录 #include &lt;jemalloc/jemalloc.h&gt; ^编译中断。make[1]: *** [adlist.o] 错误 1make[1]: 离开目录“/opt/redis-4.0.1/src”make: *** [all] 错误 2 想要弄明白这个错误是怎么回事，我们得先看一下Redis的描述文档。打开Reids根目录下的README文件，找到这么一段话：12345678910111213141516171819202122[root@localhost redis-4.0.1]# cat README.md............Allocator---------Selecting a non-default memory allocator when building Redis is done by settingthe `MALLOC` environment variable. Redis is compiled and linked against libcmalloc by default, with the exception of jemalloc being the default on Linuxsystems. This default was picked because jemalloc has proven to have fewerfragmentation problems than libc malloc.To force compiling against libc malloc, use: % make MALLOC=libcTo compile against jemalloc on Mac OS X systems, use: % make MALLOC=jemalloc............ 这是Redis在安装时关于内存分配器allocator的描述，如果指定了MALLOC这个环境变量，那么会用这个环境变量的去建立Redis。如果没有，那么就是用默认的分配器。Redis 2.4版本之后，默认使用jemalloc来做内存管理，因为jemalloc被证明解决fragmentation problems（内存碎片化问题）比libc更好。但是如果你又没有jemalloc而只有libc，当make出错时，你可以加这么一个参数即可 make MALLOC=libc。 如果我们就是想用jemalloc，那么安装jemalloc即可，该过程很简单，一般不会报错：12345[root@localhost opt]# wget https://github.com/jemalloc/jemalloc/releases/download/5.0.1/jemalloc-5.0.1.tar.bz2[root@localhost opt]# tar -xvf jemalloc-5.0.1.tar.bz2[root@localhost opt]# cd jemalloc-5.0.1/[root@localhost jemalloc-5.0.1]# ./configure --prefix=/usr/local/jemalloc[root@localhost jemalloc-5.0.1]# make &amp;&amp; make install jemalloc安装完成后，可查看安装结果：123456[root@localhost jemalloc-5.0.1]# ll /usr/local/jemalloc/总用量 0drwxr-xr-x. 2 root root 62 8月 13 10:58 bindrwxr-xr-x. 3 root root 22 8月 13 10:58 includedrwxr-xr-x. 3 root root 115 8月 13 10:58 libdrwxr-xr-x. 4 root root 28 8月 13 10:58 share 解决完上边两个问题，再次对 Redis 进行编译，就不会报错了，因为我们打算采用jemalloc管理内存，所以编译时我们需要指定内存管理器：1234567[root@localhost jemalloc-5.0.1]# cd ../redis-4.0.1/[root@localhost redis-4.0.1]# make MALLOC=/usr/local/jemalloc/lib............Hint: It's a good idea to run 'make test' ;)make[1]: 离开目录“/opt/redis-4.0.1/src” 安装编译完成后，执行 make install 进行安装，安装过程我没有发现什么错误： 12345678910[root@localhost redis-4.0.1]# cd src [root@localhost src]# make installHint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install 测试安装完成后，我们一般还要对安装结果进行测试，测试的方式很简单，在安装结果中已经说明了，执行 make test 即可。不过在进行测试的过程中，我遇到了一个错误： 123[root@localhost src]# make testYou need tcl 8.5 or newer in order to run the Redis testmake: *** [test] 错误 1 这是由于tcl的版本低于8.5导致的，安装最新的tcl即可：123456[root@localhost opt]# wget https://sourceforge.net/projects/tcl/files/Tcl/8.6.7/tcl8.6.7-src.tar.gz[root@localhost opt]# tar -zxvf tcl8.6.7-src.tar.gz -C /usr/local/[root@localhost opt]# cd /usr/local/tcl8.6.7/unix[root@localhost unix]# ./configure[root@localhost unix]# make[root@localhost unix]# make install tcl安装完成后，再次进行测试，完美通过：1234567[root@localhost redis-4.0.1]# make test............\\o/ All tests passed without errors!Cleanup: may take some time... OKmake[1]: 离开目录“/opt/redis-4.0.1/src” 查看安装版本其实安装完成后，版本看不看无所谓，反正我们自己肯定是知道自己安装的什么版本的。查看版本的命令是 redis-server -v：12[root@localhost redis-4.0.1]# redis-server -vRedis server v=4.0.1 sha=00000000:0 malloc=libc bits=64 build=573071f5c48ca889 到现在，Redis就算安装完成了，很简单吧。 服务端启动执行 redis-server redis.conf，查看我们安装的Redis是否能正常启动，如果后面没有跟redis.conf则按照默认配置启动： 1234567891011121314151617181920212223242526272829[root@localhost redis-4.0.1]# redis-server redis.conf27450:C 13 Aug 11:30:44.516 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo27450:C 13 Aug 11:30:44.516 # Redis version=4.0.1, bits=64, commit=00000000, modified=0, pid=27450, just started27450:C 13 Aug 11:30:44.516 # Configuration loaded27450:M 13 Aug 11:30:44.517 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 4.0.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 27450 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 27450:M 13 Aug 11:30:44.518 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.27450:M 13 Aug 11:30:44.518 # Server initialized27450:M 13 Aug 11:30:44.518 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.27450:M 13 Aug 11:30:44.518 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.27450:M 13 Aug 11:30:44.518 * Ready to accept connections 客户端连接服务器端启动后，再用 redis-cli -h IP -p 端口号 命令查看客户端能否正常连接，连接进入后，使用info命令可以查看你所使用的内存管理器： 12[root@localhost redis-4.0.1]# redis-cli -h 127.0.0.1 -p 6379127.0.0.1:6379&gt; info 根据自己使用的内存管理器不同有如下两种结果:12mem_allocator:libcmem_allocator:jemalloc-4.0.3 好了，Redis安装完了，下一讲，我们再说一下Redis的各个配置项。","tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.jkinn.com/tags/Redis/"}]},{"title":"MySQL 深入探讨（一）： 阿里云 Linux CentOS 7.3 安装配置 JDK-1.8、MySQL-5.7","date":"2017-04-10T07:48:14.000Z","path":"2017/04/10/2017041001/","text":"最初公司购买的阿里云服务器是Linux CentOS 6.8版本的，在安装MySQL 5.7的过程中遇到了一些问题，系统总是提示各种依赖包不存在。折腾了一天，打败了好多小怪兽后最后总算安装好了，遗憾的是，当时的安装过程没有做记录。这几天公司又采购了一台阿里云，还是由我来搭建生产环境，为了以后公司有新的服务器加入时，弟兄们能无脑搭建环境，这次的安装过程我做了详细记录，其他的服务器版本不敢说，阿里云 CentOS 7.3 的服务器按照这个过程基本不会出现什么问题。 已安装版本查看及卸载因为我们的服务器是新采购的，上面什么东西都没有安装，甚至连JDK也没有，所以安装前我不需要检查软件是否安装，如果阁下的服务器是正在使用的，建议先检查某个软件是否已经安装，如果已经安装，需要咨询下领导是否要重新安装或者是否可移除。 12345-- 检查软件是否已经安装，以MySQL为例[root@服务器主机名 opt]# rpm -qa | grep -i mysqlmysql-community-release-el7-5.noarch-- 如果有安装组件，则需要一个个的卸载掉[root@服务器主机名 opt]# yum -y remove mysql-community-release-el7-5 系统版本查看我们才接收到公司采购的服务器时，基本都知道自己的服务器版本信息，当然有些情况我们是不知道服务器版本信息的，在这里我们先查询一下服务器信息： 12345678910111213141516171819202122232425262728293031323334-- 查看系统内核版本[root@服务器主机名 ~]# uname -aLinux 服务器主机名 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux[root@服务器主机名 ~]# cat /proc/versionLinux version 3.10.0-514.21.1.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) ) #1 SMP Thu May 25 17:04:51 UTC 2017-- 查看系统发行版本[root@服务器主机名 ~]# lsb_release -aLSB Version: :core-4.1-amd64:core-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.3.1611 (Core) Release: 7.3.1611Codename: Core[root@服务器主机名 ~]# cat /etc/os-releaseNAME=\"CentOS Linux\"VERSION=\"7 (Core)\"ID=\"centos\"ID_LIKE=\"rhel fedora\"VERSION_ID=\"7\"PRETTY_NAME=\"CentOS Linux 7 (Core)\"ANSI_COLOR=\"0;31\"CPE_NAME=\"cpe:/o:centos:centos:7\"HOME_URL=\"https://www.centos.org/\"BUG_REPORT_URL=\"https://bugs.centos.org/\"CENTOS_MANTISBT_PROJECT=\"CentOS-7\"CENTOS_MANTISBT_PROJECT_VERSION=\"7\"REDHAT_SUPPORT_PRODUCT=\"centos\"REDHAT_SUPPORT_PRODUCT_VERSION=\"7\"[root@服务器主机名 ~]# cat /etc/redhat-releaseCentOS Linux release 7.3.1611 (Core) [root@服务器主机名 ~]# rpm -q centos-releasecentos-release-7-3.1611.el7.centos.x86_64...... 安装 JDK 1.8我安装的时候JDK的最高版本是jdk-8u131，所以此处就以jdk-8u131为例进行安装，其他版本也一样：123456789101112131415-- 安装JDK[root@服务器主机名 opt]# rpm -ivh jdk-8u131-linux-x64.rpm Preparing... ################################# [100%]Updating / installing... 1:jdk1.8.0_131-2000:1.8.0_131-fcs ################################# [100%]Unpacking JAR files... tools.jar... plugin.jar... javaws.jar... deploy.jar... rt.jar... jsse.jar... charsets.jar... localedata.jar......... 安装完成后，查看JDK版本信息以判断是否安装成功：12345-- 查看JDK版本信息[root@服务器主机名 opt]# java -versionjava version \"1.8.0_131\"Java(TM) SE Runtime Environment (build 1.8.0_131-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode) 安装 MySQL 5.7原则上在安装前，我们需要检查一下MySQL是否已经安装，因为我的服务器是全新的，不需要检查，此处我直接安装，如果阁下的服务器已经安装了软件，则回到本文前言处查看如何检查是否已安装MySQL。此处我选择了rpm包安装的方式，这种方式比较快速，而且安装过程简单，为了方便兄弟们判断自己的安装过程是否正确，我把安装过程的大部分日志贴出来了供各位对比：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169-- 下载MySQL 5.7 rpm 安装包[root@服务器主机名 opt]# wget http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm--2017-06-20 10:45:38-- http://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpmResolving dev.mysql.com (dev.mysql.com)... 137.254.60.11Connecting to dev.mysql.com (dev.mysql.com)|137.254.60.11|:80... connected.HTTP request sent, awaiting response... 301 Moved PermanentlyLocation: https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm [following]--2017-06-20 10:45:38-- https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpmConnecting to dev.mysql.com (dev.mysql.com)|137.254.60.11|:443... connected.HTTP request sent, awaiting response... 302 FoundLocation: https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpm [following]--2017-06-20 10:45:40-- https://repo.mysql.com//mysql57-community-release-el7-11.noarch.rpmResolving repo.mysql.com (repo.mysql.com)... 23.10.6.195Connecting to repo.mysql.com (repo.mysql.com)|23.10.6.195|:443... connected.HTTP request sent, awaiting response... 200 OKLength: 25680 (25K) [application/x-redhat-package-manager]Saving to: ‘mysql57-community-release-el7-11.noarch.rpm’100%[==================================================================================================================================&gt;] 25,680 --.-K/s in 0.06s 2017-06-20 10:45:40 (421 KB/s) - ‘mysql57-community-release-el7-11.noarch.rpm’ saved [25680/25680]-- 安装MySQL rpm 安装包，一路除了输入[y]就是回车[root@服务器主机名 opt]# yum localinstall mysql57-community-release-el7-11.noarch.rpmLoaded plugins: fastestmirrorExamining mysql57-community-release-el7-11.noarch.rpm: mysql57-community-release-el7-11.noarchMarking mysql57-community-release-el7-11.noarch.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package mysql57-community-release.noarch 0:el7-11 will be installed--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================ Package Arch Version Repository Size============================================================================================================================================================================Installing: mysql57-community-release noarch el7-11 /mysql57-community-release-el7-11.noarch 31 kTransaction Summary============================================================================================================================================================================Install 1 PackageTotal size: 31 kInstalled size: 31 k-- 输入 yIs this ok [y/d/N]: yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transactionWarning: RPMDB altered outside of yum. Installing : mysql57-community-release-el7-11.noarch 1/1 Verifying : mysql57-community-release-el7-11.noarch 1/1 Installed: mysql57-community-release.noarch 0:el7-11 Complete!-- 查看刚才的安装过程是否成功（看看安装了哪些MySQL组件即可）[root@服务器主机名 opt]# yum repolist enabled | grep \"mysql.*-community.*\"mysql-connectors-community/x86_64 MySQL Connectors Community 36mysql-tools-community/x86_64 MySQL Tools Community 47mysql57-community/x86_64 MySQL 5.7 Community Server 187-- 安装MySQL服务器，同样一路除了输入[y]就是回车[root@服务器主机名 opt]# yum install mysql-community-serverLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comResolving Dependencies--&gt; Running transaction check---&gt; Package mysql-community-server.x86_64 0:5.7.18-1.el7 will be installed--&gt; Processing Dependency: mysql-community-common(x86-64) = 5.7.18-1.el7 for package: mysql-community-server-5.7.18-1.el7.x86_64--&gt; Processing Dependency: mysql-community-client(x86-64) &gt;= 5.7.9 for package: mysql-community-server-5.7.18-1.el7.x86_64--&gt; Processing Dependency: libaio.so.1(LIBAIO_0.4)(64bit) for package: mysql-community-server-5.7.18-1.el7.x86_64--&gt; Processing Dependency: libaio.so.1(LIBAIO_0.1)(64bit) for package: mysql-community-server-5.7.18-1.el7.x86_64--&gt; Processing Dependency: libaio.so.1()(64bit) for package: mysql-community-server-5.7.18-1.el7.x86_64--&gt; Running transaction check---&gt; Package libaio.x86_64 0:0.3.109-13.el7 will be installed---&gt; Package mysql-community-client.x86_64 0:5.7.18-1.el7 will be installed--&gt; Processing Dependency: mysql-community-libs(x86-64) &gt;= 5.7.9 for package: mysql-community-client-5.7.18-1.el7.x86_64---&gt; Package mysql-community-common.x86_64 0:5.7.18-1.el7 will be installed--&gt; Running transaction check---&gt; Package mariadb-libs.x86_64 1:5.5.52-1.el7 will be obsoleted--&gt; Processing Dependency: libmysqlclient.so.18()(64bit) for package: 2:postfix-2.10.1-6.el7.x86_64--&gt; Processing Dependency: libmysqlclient.so.18(libmysqlclient_18)(64bit) for package: 2:postfix-2.10.1-6.el7.x86_64---&gt; Package mysql-community-libs.x86_64 0:5.7.18-1.el7 will be obsoleting--&gt; Running transaction check---&gt; Package mysql-community-libs-compat.x86_64 0:5.7.18-1.el7 will be obsoleting--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================================================================================================================ Package Arch Version Repository Size============================================================================================================================================================================Installing: mysql-community-libs x86_64 5.7.18-1.el7 mysql57-community 2.1 M replacing mariadb-libs.x86_64 1:5.5.52-1.el7 mysql-community-libs-compat x86_64 5.7.18-1.el7 mysql57-community 2.0 M replacing mariadb-libs.x86_64 1:5.5.52-1.el7 mysql-community-server x86_64 5.7.18-1.el7 mysql57-community 162 MInstalling for dependencies: libaio x86_64 0.3.109-13.el7 base 24 k mysql-community-client x86_64 5.7.18-1.el7 mysql57-community 24 M mysql-community-common x86_64 5.7.18-1.el7 mysql57-community 271 kTransaction Summary============================================================================================================================================================================Install 3 Packages (+3 Dependent packages)Total download size: 190 M-- 输入 yIs this ok [y/d/N]: yDownloading packages:(1/6): libaio-0.3.109-13.el7.x86_64.rpm | 24 kB 00:00:00 warning: /var/cache/yum/x86_64/7/mysql57-community/packages/mysql-community-common-5.7.18-1.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEYPublic key for mysql-community-common-5.7.18-1.el7.x86_64.rpm is not installed(2/6): mysql-community-common-5.7.18-1.el7.x86_64.rpm | 271 kB 00:00:00 (3/6): mysql-community-libs-5.7.18-1.el7.x86_64.rpm | 2.1 MB 00:00:00 (4/6): mysql-community-libs-compat-5.7.18-1.el7.x86_64.rpm | 2.0 MB 00:00:00 (5/6): mysql-community-client-5.7.18-1.el7.x86_64.rpm | 24 MB 00:00:02 (6/6): mysql-community-server-5.7.18-1.el7.x86_64.rpm | 162 MB 00:00:15 ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------Total 12 MB/s | 190 MB 00:00:16 Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysqlImporting GPG key 0x5072E1F5: Userid : \"MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;\" Fingerprint: a4a9 4068 76fc bd3c 4567 70c8 8c71 8d3b 5072 e1f5 Package : mysql57-community-release-el7-11.noarch (installed) From : /etc/pki/rpm-gpg/RPM-GPG-KEY-mysql-- 输入 yIs this ok [y/N]: yRunning transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : mysql-community-common-5.7.18-1.el7.x86_64 1/7 Installing : mysql-community-libs-5.7.18-1.el7.x86_64 2/7 Installing : mysql-community-client-5.7.18-1.el7.x86_64 3/7 Installing : libaio-0.3.109-13.el7.x86_64 4/7 Installing : mysql-community-server-5.7.18-1.el7.x86_64 5/7 Installing : mysql-community-libs-compat-5.7.18-1.el7.x86_64 6/7 Erasing : 1:mariadb-libs-5.5.52-1.el7.x86_64 7/7 Verifying : mysql-community-server-5.7.18-1.el7.x86_64 1/7 Verifying : mysql-community-common-5.7.18-1.el7.x86_64 2/7 Verifying : mysql-community-client-5.7.18-1.el7.x86_64 3/7 Verifying : mysql-community-libs-compat-5.7.18-1.el7.x86_64 4/7 Verifying : libaio-0.3.109-13.el7.x86_64 5/7 Verifying : mysql-community-libs-5.7.18-1.el7.x86_64 6/7 Verifying : 1:mariadb-libs-5.5.52-1.el7.x86_64 7/7 Installed: mysql-community-libs.x86_64 0:5.7.18-1.el7 mysql-community-libs-compat.x86_64 0:5.7.18-1.el7 mysql-community-server.x86_64 0:5.7.18-1.el7 Dependency Installed: libaio.x86_64 0:0.3.109-13.el7 mysql-community-client.x86_64 0:5.7.18-1.el7 mysql-community-common.x86_64 0:5.7.18-1.el7 Replaced: mariadb-libs.x86_64 1:5.5.52-1.el7 Complete! 这样 MySQL 就安装完成了，简单吧，其实只要系统没有缺少依赖包，安装MySQL就不会出现什么问题。好了，接下来我们启动MySQL服务： 1234567891011121314151617181920212223-- 安装完毕，启动MySQL服务 [root@服务器主机名 opt]# systemctl start mysqld-- 查看MySQL状态[root@服务器主机名 opt]# systemctl status mysqld● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 10:50:44 CST; 12s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 20502 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 20426 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 20504 (mysqld) CGroup: /system.slice/mysqld.service └─20504 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pidJun 20 10:50:39 服务器主机名 systemd[1]: Starting MySQL Server...Jun 20 10:50:44 服务器主机名 systemd[1]: Started MySQL Server.-- 当然你也可以这样启动MySQL服务[root@服务器主机名 opt]# systemctl enable mysqld-- 重新加载配置文件[root@服务器主机名 opt]# systemctl daemon-reload 现在小伙伴们应该有个疑问，安装过程中没有配置访问密码，那我们的数据库密码是多少呢？甭担心，安装过程中 MySQL 生成了首次访问的默认密码，通过以下命令我们就可以查找到 MySQL 的访问密码： 123-- 查询 MySQL 默认密码[root@服务器主机名 opt]# grep 'temporary password' /var/log/mysqld.log2017-06-20T02:50:40.691736Z 1 [Note] A temporary password is generated for root@localhost: Oot)8y;ih&gt;#K 看见了没，root@localhost:后边的 Oot)8y;ih&gt;#K 就是我们的 MySQL 密码。 现在我们就可以进入我们的MySQL玩耍了,首先我们要做的就是修改 root 账户的密码，毕竟默认密码太不安全了（这里需要注意的是，MySQL 5.7的密码安全性验证很强，需要同时包含有大写字母、小写字母、特殊符号、数字，并且长度不能少于8位）： 1234567891011121314151617181920-- 登录MySQL[root@服务器主机名 opt]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.7.18Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY '你的密码';Query OK, 0 rows affected (0.00 sec)mysql&gt; quitBye 在正式使用 MySQL 时，我们肯定不能使用root用户操作数据库，因为root用户的权限太大，稍不留神，手一抖数据库就废了，所以下一步我们需要创建一个普通用户： 1234567891011121314151617181920-- 登录MySQL[root@服务器主机名 opt]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 4Server version: 5.7.18 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; GRANT ALL PRIVILEGES ON *.* TO '用户名'@'%' IDENTIFIED BY '用户密码' WITH GRANT OPTION;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; quitBye 测试我们新建的用户是否能登录： 1234567891011121314151617[root@服务器主机名 opt]# mysql -uzxjy -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 5Server version: 5.7.18 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt;...... 由于公司规定数据库的编码都必须是utf-8，所以接下来我们需要把 MySQL 的数据库编码改为 utf-8。编辑 MySQL 的配置文件，在其中添加character_set_server=utf8、init_connect=’SET NAMES utf8’两句，如下所示： 123456789101112131415161718192021222324252627282930313233[root@服务器主机名 opt]# cat /etc/my.cnf# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html[mysqld]#添加下边这两句character_set_server=utf8init_connect='SET NAMES utf8'## Remove leading # and set to the amount of RAM for the most important data# cache in MySQL. Start at 70% of total RAM for dedicated server, else 10%.# innodb_buffer_pool_size = 128M## Remove leading # to turn on a very important data integrity option: logging# changes to the binary log between backups.# log_bin## Remove leading # to set options mainly useful for reporting servers.# The server defaults are faster for transactions and fast SELECTs.# Adjust sizes as needed, experiment to find the optimal values.# join_buffer_size = 128M# sort_buffer_size = 2M# read_rnd_buffer_size = 2Mdatadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pid 查看编码是否修改： 123456789101112131415161718192021222324252627282930-- 重启MySQL[root@服务器主机名 opt]# systemctl restart mysqld[root@服务器主机名 opt]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 3Server version: 5.7.18 MySQL Community Server (GPL)Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.mysql&gt; show variables like '%character%';+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.01 sec) 好了，到现在，我们的MySQL就安装完成了，具体的配置就看阁下公司内部的具体规定了。","tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://www.jkinn.com/tags/MySQL/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（六） —— Markdown常用语法及工具","date":"2017-01-09T02:39:52.000Z","path":"2017/01/09/2017010901/","text":"","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（五） —— 博客链接提交百度、谷歌等搜索引擎收录","date":"2017-01-08T09:22:32.000Z","path":"2017/01/08/2017010801/","text":"","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（四） —— 使用七牛云作为博客图床","date":"2017-01-07T09:21:08.000Z","path":"2017/01/07/2017010701/","text":"前面三个小节，我们实现了博客搭建及绑定个人域名，到目前我们的博客其实已经搭建完成了，本节属于博客优化。我们之前把博客部署在了Github、Coding、码云上，Giehub和码云好说，空间比较大，但是Coding给我们的存储空间只有256M，试想如果我们博客中的图片很多，一篇博客有那么十来张图片，那么一篇博客的大小最低也得超出1M甚至几兆了，而博客的文字只占很小的一部分空间，大部分空间都让图片占去了。既然这样，我们能不能把图片和文字分开，图片存储在专门的图床上，我们只调取链接呢，这样不就极大的减少了博客占据的空间了吗。 下面我们就说一下如何将图片存储在图床上。 现在国内免费的图床有很多，比如：贴图库http://www.tietuku.com/、图床http://tuchuang.org/、极简图床http://jiantuku.com/#/等等。当然腾讯云、阿里云、七牛云这些收费的云平台也可以作为图床使用。免费的我们就不说了，很简单，本节我们只说一下七牛云。七牛云也提供了免费的空间，当然不是全免费，在一定存储范围内免费，而且每月有10G的免费访问流量，其实一般来说，只要正常访问也够用了。 首先登录七牛云，找到 对象存储——&gt; 立即添加： Markdown 新建存储空间，如下图所示，这里的空间一定要选公开空间： Markdown 空间创建后，进入 内容管理： Markdown 点击 上传文件： Markdown 上传我们的图片就可以了，上传后点击 关闭 按钮回到文件列表： Markdown 在文件列表的操作项上点击 复制外链 ，就可以拿到我们的图片外网访问地址了： Markdown 然后我们把地址插进 Markdown 的编辑器就可以了。 注意：七牛云每月提供的10G流量在正常情况下可以满足，但是如果有小伙伴拿到你的图片地址，随便写个网络请求的小程序，外加个死循环，呵呵，那这10G的流量分分钟就给你玩没了，超出的流量可就是收费的了。这个问题目前来说无解，谁让咱们用的人家免费的呢。","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（三） —— 绑定个人域名","date":"2017-01-06T09:18:41.000Z","path":"2017/01/06/2017010601/","text":"经过前面两个小节的搭建，我们的博客已经实现了外网访问，其实只要不介意地址，博客就可以用了。今天我们来说一下如何使用自己申请的域名访问博客，当然，前提是你已经购买了域名。在第二小节中，我们把博客发布在了Github、Coding、码云这三个平台上，在绑定域名时，可以选择其中一个平台进行绑定，也可以一个域名根据线路不同绑定多个平台，比如海外用户访问Github，国内用户访问Coding或者码云。 首先，我们登录Coding，依次选择 代码——&gt; Pages服务，在 自定义域名处填写自己的域名，这里可以写多个： Markdown 然后登录我们的域名系统，这里我是购买的万网的域名，找到域名解析——&gt;立即设置： Markdown 然后选择 进入高级设置： Markdown 这里先科普一下，什么是记录类型和主机记录，常用的记录类型是 CNAME记录和A记录，简单说就是CNAME记录是绑定域名，A记录是绑定IP地址： Markdown 主机记录就是你的域名在浏览器地址栏怎么写，www就是域名带www，@就是域名不带www: Markdown 添加解析记录就很简单了，这里你可以用之前我们访问的地址（xxxx.github.io、xxx.coding.me、xxxx.oschina.io），也可以用IP地址，可以找一个平台绑定，也可以根据解析线路不同绑定多个平台，具体解析如下： Markdown 有的兄弟可能会问，我哪知道他的IP多少，ping命令会吧，ping一下地址不就出来了： Markdown 到这里还没完呢，这时候我们可以通过域名访问，但是访问会提示403,这时候需要在博客根目录的source子目录下建一个名为【CNAME】的文本文件，然后把文件的后缀名干掉，这个文件里写什么呢，就是你的域名，如下图所示： Markdown 最后依次执行 hexo g、hexo d 待执行完毕，我们就可以用自己的域名访问博客了。","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（二） —— 托管至Coding、Github、码云（oschina）","date":"2017-01-05T09:01:27.000Z","path":"2017/01/05/2017010501/","text":"前言在上一节中，我们在本地用Hexo搭建起了个人博客，并实现了发布及本地访问，本节我们学习将本地搭建好的博客发布到Github、Coding、码云上，实现外网访问。同时发布到多个托管平台一是为了下一节绑定域名时能够做到国内外访问分流，以提高各自的访问速度，二是为了在某一托管平台不能访问时，我们的博客能切换至其他平台继续对外发布。 至于Github、Coding和码云这三大代码托管平台怎么注册我就不说了，以下过程建立在三个代码托管平台均已注册的基础上。 托管至Github首先，我们说一下如何将本地的博客发布到Github上。登录Github后，点击右上角小加号，找到New repository，点击，创建新的资源库： Markdown 这里的资源库名字要注意了哈，资源库的名字格式是固定的，格式为：你的Github账户名.github.io，即如果你的Github账户名是zhangsan，则你的资源库名称为：zhangsan.github.io，千万千万不要乱写，格式不对，等会浏览器是访问不了的，点击Create repository创建资源库： Markdown 资源库创建后，复制资源库地址，如下图所示： Markdown 打开博客目录（上节我们新建的那个文件夹）下的_config.yml文件，找到deploy节点，将刚才复制的Github资源库地址配置上： 12345deploy: type: git repo: github: git@github.com:你的github帐户名/你的github帐户名.github.io.git branch: master 接下来我们安装部署插件，右键打开Git Bash，输入 npm install hexo-deployer-git –save 进行安装： 12345678dell@wanghl MINGW64 /d/blog$ npm install hexo-deployer-git --savehexo-site@0.0.0 D:\\blog`-- hexo-deployer-git@0.3.0 `-- moment@2.18.1npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\\ch okidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@ 1.1.2: wanted &#123;\"os\":\"darwin\",\"arch\":\"any\"&#125; (current: &#123;\"os\":\"win32\",\"arch\":\"x64\"&#125;) 然后依次执行 hexo g、hexo d 进行编译、部署的时候有可能会报下图所示的错误： Markdown 这个错误的意思是没有权限提交，这很正常，因为Github根本不认识我们的电脑，肯定没有权限。在C盘下找到.ssh目录： Markdown 如果刚才报错的话，这个目录要么是空的要么只有一个 known_hosts 文件。在刚才的命令窗口执行 ssh-keygen -t rsa -C “注册github时候用的邮箱”（C是大写的）： 12dell@wanghl MINGW64 /d/blog$ ssh-keygen -t rsa -C \"注册github时候用的邮箱\" Markdown 这时候我们会发现 .ssh 目录下生成了两个文件 id_rsa.pub 和 id_rsa ： Markdown 用文本编辑器打开 id_rsa.pub 文件，全选复制里面的内容，找到Github下的个人设置： Markdown 找到 SSH and GPG keys ，点击右上角的 New SSH key： Markdown Title随便起名字，将刚才复制的内容黏贴到 Key 文本域中，点击 Add SSH key 保存。 Markdown 然后在控制台输入 ssh -T git@github.com 测试是否验证通过，控制台输出如下信息表示权限验证通过： 123dell@wanghl MINGW64 /e/blog$ ssh -T git@github.comHi 你的帐户名! You've successfully authenticated, but GitHub does not provide shell access. 然后再次执行 hexo d 提交部署，就可以部署成功了： Markdown 在浏览器访问 你的项目名称（即帐户名.github.io），就可以看到我们发布的博客了： Markdown 至此，将本地的Hexo博客发布到Github操作就算完成了，接下来我们再将其发布到Coding。 托管至Coding登录 Coding ，依次找到 账户——&gt;SSH公钥 ，和上边添加Github公钥一样添加我们生成的公钥： Markdown 然后点击 添加项目 添加我们要发布博客的项目： Markdown 项目名和帐户名保持一致，这里就不需要后缀了，直接写帐户名就好，项目类型选为 私有 ，点击 创建项目 进行创建： Markdown 项目创建后，会自动跳转到项目页面，点击 代码 ，找到 SSH 方式访问仓库，然后复制仓库地址： Markdown 打开博客目录（上节我们新建的那个文件夹）下的_config.yml文件，找到deploy节点，将刚才复制的仓库 SSH 访问地址 配置上，这时候我们的仓库就是两个了，一个是上边配置的Github，一个是Coding： 123456deploy: type: git repo: github: git@github.com:你的帐户名/你的帐户名.github.io.git coding: git@git.coding.net:你的帐户名/你的帐户名.git branch: master 这时，我们再次依次执行 hexo g、hexo d，进行生成、发布，在发布时，会提示如下信息，意思就是是不是要连接到Coding，输入 yes ，点击 OK 继续 Markdown 这时候控制台会出现两份提交信息，一条是提交到Github，一条是提交到Coding: Markdown 进入Coding项目，点击代码，就能看到我们提交上来的文件了，其实这些文件就是博客目录下public子目录中的东西： Markdown 选择 代码——&gt; Pages 服务，部署来源选择 Master分支 ，点击 保存 对项目进行静态发布： Markdown 出现下边的信息表示项目发布成功，这时候我们可以将 强制 HTTPS 访问 打开，增强博客安全性： Markdown 最后，在浏览器访问 你的项目名.coding.me，看到我们的博客页面，表示部署成功： Markdown OK，又搞定一个代码托管平台，继续搞定 码云 ！ 托管至码云有了上边两个平台的经验，码云就非常简单了，同样，第一步先授权。登录码云，依次点击 头像——&gt; 个人资料——&gt; SSH 公钥，将我们生成的SSH公钥填进去，确定保存： Markdown 点击 新建项目 创建项目，项目名必须，必须，必须和用户名保持一致，语言类型选择 HTML，点击创建： Markdown 创建完成后，会跳转至项目页，复制项目 SSH 地址： Markdown 同样，将项目的 SSH 地址配置在博客的配置文件中： 1234567deploy: type: git repo: github: git@github.com:你的github帐户名/你的项目名.github.io.git coding: git@git.coding.net:你的Coding帐户名/你的项目名.git oschina: git@git.oschina.net:你的码云帐户名/你的项目名.git branch: master 然后执行 hexo d 进行发布，这时，也会有提示，和Coding一样，输入 yes 点击 OK： Markdown 刷新码云项目页，就可以看到我们发布的文件了： Markdown 点击项目操作项 服务——&gt; Pages，部署分支选择 Master，点击 启动服务 ，开启Pages 服务： Markdown 部署成功后，系统会返回访问地址，其实就是 你的项目名.oschina.io: Markdown 在浏览器访问部署地址，看到我们的博客主页，表示部署成功： Markdown 到现在，三大主流托管平台我们都已经搞定了。其实现在我们已经可以在外网访问我们的博客了，但是访问地址并不是我们自己的域名，看起来有点Low，下一节，我们说一下如何把访问地址改成自己的域名。","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]},{"title":"零基础 Hexo + Coding、Github、码云(oschina)搭建个人博客（一） —— 基础环境搭建","date":"2017-01-04T08:05:05.000Z","path":"2017/01/04/2017010401/","text":"前言&nbsp;&nbsp;&nbsp;&nbsp;能用来搭建个人博客的工具很多，本文只对Hexo做介绍。&nbsp;&nbsp;&nbsp;&nbsp;Hexo可用来搭建个人博客，并可依据国内外网络环境同时部署在Github和Coding(码云)上，国外用户访问Github，国内用户访问Coding，即加快国内访问速度，又可实现博客访问分流。用Hexo搭建个人博客，不仅所需的所有软件及部署平台均免费，而且搭建过程也是非常简单的，您只需要按照小编给您写好的步骤不停的下一步即可。 软件列表整个搭建过程需要安装的软件并不多，全部所需软件如下（版本无所谓）： Markdown 各软件下载地址如下： 软件 下载地址 Git-2.13.2-64-bit.exe https://git-scm.com/downloads node-v6.11.0-x64.msi https://nodejs.org/en/download/ TortoiseGit-2.4.0.2-64bit.msi https://tortoisegit.org/download/ TortoiseGit-LanguagePack-2.4.0.0-64bit-zh_CN.msi https://tortoisegit.org/download/ 如果您已经安装过这几个软件，则可跳过本文，直接进入下一步： Git 安装首先我们需要安装Git，Git是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。在搭建博客的过程中，我们主要使用Git的命令行进行Hexo的安装及配置。 双击Git-2.13.2-64-bit.exe，开始安装Git: Markdown 点击Next,进入下一步： Markdown 选择安装目录，点击Next，进入下一步： Markdown 全部勾选，特别是需要勾选Git Bash Here和Git GUI Here这两个选项，点击Next，进入下一步： Markdown 默认，点击Next，进入下一步： Markdown 选择第二项 Use Git from the Windows Command Prompt ,点击Next，进入下一步： Markdown 默认，点击Next，进入下一步： Markdown 选择第一项Checkout Windows-style,comment Unix-style line endings，点击Next，进入下一步： Markdown 选择第一项Use MinTTY， 点击Next，进入下一步： Markdown 默认，点击Next，开始安装： Markdown 稍等片刻，弹出如下界面，表示安装完毕： Markdown 在电脑任意文件夹，右键，能在右键操作列表中看到如下红圈标识的两项操作，表示Git安装成功： Markdown TortoiseGit 安装及配置Git自带的操作方式为命令行，命令行的方式对非IT行业的小伙伴来说并不是很友好，为了方便Git的使用，我们还需要安装TortoiseGit。TortoiseGit是一个开放的git版本控制系统的客户端，他将Git原生的命令行操作方式转为界面方式，极大的降低了Git的学习成本。 双击TortoiseGit-2.4.0.2-64bit.msi，开始安装TortoiseGit： Markdown 点击Next，进入下一步： Markdown 点击Next，进入下一步： Markdown 默认，点击Next，进入下一步： Markdown 点击 install，开始安装TortoiseGit： Markdown 稍等片刻，弹出如下界面，表示安装完毕： Markdown 在电脑任意文件夹，右键，能在右键操作列表中看到如下红圈标识的三项操作，表示TortoiseGit安装成功： Markdown 这时候，我们已经把Git的命令行界面简化成了鼠标操作，但是操作按钮全都是英文的，对于英文不是那么好的小伙伴来说，貌似还是不那么友好，接下来我们继续把TortoiseGit的英文界面简化成中文。 双击 TortoiseGit-LanguagePack-2.4.0.0-64bit-zh_CN.msi，安装中文语言包： Markdown 点击 下一步： Markdown 一眨眼的功夫，就安装完了，点击 完成 退出。在任意文件夹右键，找到 TortoiseGit ——&gt; Settings： Markdown 找到 General ——&gt; Language，将语言改为 【中文】保存： Markdown 这时候TortoiseGit的操作按钮就是中文的了，如下图： Markdown 至此，我们已经完成了TortoiseGit的安装。 nodeJS 安装Node.js是一个Javascript运行环境(runtime)，就是运行在服务端的 JavaScript。在使用Hexo搭建博客的过程中，NodeJS扮演着十分重要的角色，它提供了Hexo的安装环境。 NodeJS的安装也很简单，只需下一步下一步即可。双击node-v6.11.0-x64.msi 开始安装： Markdown 点击Next，进入下一步： Markdown 勾选同意条款，点击Next，进入下一步： Markdown 选择安装目录，点击Next，进入下一步： Markdown 默认，点击Next，进入下一步： Markdown 点击install，开始安装： Markdown 稍等片刻，弹出如下界面，表示安装完毕： Markdown 点击Finish，退出！ Hexo 安装及配置准备好以上两个工具后，就正式迎来了我们今天的主角【Hexo】,Hexo不需要提前准备安装文件，只需要几个简单的命令即可。安装过程和以上两个工具一样，也是非常简单的，OK，走起来。 在电脑的某个目录下新建一个文件夹，名字随便取，只要不是中文的就好，我这里在E盘下新建文件夹blog。打开刚建好的文件夹，右键选择Git Bash Here，如下图所示： Markdown 在弹出的命令窗口中输入：npm install -g hexo ，回车： 12dell@wanghl MINGW64 /d/blog$ npm install -g hexo 稍等片刻，控制台输出以下内容表示hexo安装完成： 12npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\\hexo\\node_modules\\chokidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted &#123;\"os\":\"darwin\",\"arch\":\"any\"&#125; (current: &#123;\"os\":\"win32\",\"arch\":\"x64\"&#125;) 在控制台输入hexo -v ，验证hexo是否安装成功： 12345678910111213dell@wanghl MINGW64 /d/blog$ hexo -vhexo-cli: 1.0.3os: Windows_NT 10.0.10240 win32 x64http_parser: 2.7.0node: 6.11.0v8: 5.1.281.102uv: 1.11.0zlib: 1.2.11ares: 1.10.1-DEVicu: 58.2modules: 48openssl: 1.0.2k 控制台输出以上信息，标识hexo安装成功。接着输入hexo init进行初始化操作： 12dell@wanghl MINGW64 /d/blog$ hexo init 稍等片刻，控制台输出以下信息，标识hexo初始化成功： 123npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\\chokidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted &#123;\"os\":\"darwin\",\"arch\":\"any\"&#125; (current: &#123;\"os\":\"win32\",\"arch\":\"x64\"&#125;)INFO Start blogging with Hexo! 输入npm install，安装hexo依赖包： 1234dell@wanghl MINGW64 /d/blog$ npm installnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\\chokidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted &#123;\"os\":\"darwin\",\"arch\":\"any\"&#125; (current: &#123;\"os\":\"win32\",\"arch\":\"x64\"&#125;) 到现在hexo就算安装完成了，接下来我们就可以欣赏我们的安装成果了。 测试在刚才打开的控制台输入hexo g，生成静态化页面： 12dell@wanghl MINGW64 /d/blog$ hexo g 生成完毕后，输入hexo s，启动本地服务器 1234dell@wanghl MINGW64 /d/blog$ hexo sINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 然后打开浏览器，访问http://localhost:4000/，就可以看到我们的博客页面了： Markdown 现在我们已经在本地搭建好了自己的博客系统，下一节我们介绍如何将本地的博客托管到Github、Coding、码云等代码托管平台上。","tags":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://www.jkinn.com/tags/博客搭建/"}]}]